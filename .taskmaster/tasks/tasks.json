{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Scaffolding and Database Schema Setup",
        "description": "Initialize the FastAPI project structure, configure environment variables, and establish the database connection to Supabase. Define all required data models using SQLAlchemy and set up Alembic for database migrations.",
        "details": "Create a new Python project with FastAPI. Set up a `.env` file for configuration (SUPABASE_URL, SUPABASE_SERVICE_KEY, JWT_SECRET, etc.). Define SQLAlchemy models for `users`, `entries`, `weeks`, `teams`, `games`, `picks`, `password_reset_tokens`, and `settings` as specified in the PRD. Initialize Alembic and generate the initial migration script to create all tables in the Supabase Postgres database.",
        "testStrategy": "Run the initial Alembic migration against a local or staging Supabase instance. Verify that all tables and columns are created correctly by inspecting the database schema. Ensure the FastAPI application can successfully connect to the database on startup.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement User Authentication Endpoints",
        "description": "Develop the core user authentication system, including registration, login with JWT generation, a protected 'me' endpoint to fetch user details, and logout.",
        "details": "Implement the following endpoints in FastAPI: `POST /api/auth/register` (hashes password with passlib), `POST /api/auth/login` (verifies credentials, returns JWT), and `GET /api/auth/me` (requires valid JWT, returns user data). Use PyJWT for token encoding/decoding. Create a dependency injection utility to get the current user from a valid JWT in the Authorization header.",
        "testStrategy": "Unit test user registration with valid and invalid data (e.g., duplicate email). Test login with correct and incorrect credentials. Test the `/api/auth/me` endpoint by providing a valid token, an invalid/expired token, and no token to verify protection.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement /api/auth/register Endpoint",
            "description": "Create the user registration endpoint. This includes defining the user creation Pydantic model, implementing the API route logic to create a new user in the database, and hashing the user's password using `passlib` before storage.",
            "dependencies": [],
            "details": "Define Pydantic models for user registration request and response. Create the database model for the User. Implement the `POST /api/auth/register` endpoint in FastAPI. Add logic to hash the incoming password using `passlib`. Handle potential database errors, such as a user with the same email already existing.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement /api/auth/login Endpoint and JWT Generation",
            "description": "Develop the user login endpoint. This involves verifying the user's credentials (email and password) against the database and, upon successful verification, generating a JSON Web Token (JWT) using `PyJWT`.",
            "dependencies": [
              "2.1"
            ],
            "details": "Define Pydantic models for the login request. Implement the `POST /api/auth/login` endpoint. Add logic to fetch the user by email from the database. Use `passlib` to verify the provided password against the stored hash. If credentials are valid, create a JWT payload containing user identifiers (e.g., user ID) and encode it using `PyJWT`. Handle incorrect login attempts.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement JWT Dependency and Protected /api/auth/me Endpoint",
            "description": "Create a reusable FastAPI dependency to validate JWTs from the `Authorization` header and extract the current user. Use this dependency to protect the `/api/auth/me` endpoint, which should return the authenticated user's details.",
            "dependencies": [
              "2.2"
            ],
            "details": "Create a reusable FastAPI dependency function that extracts the token from the `Authorization: Bearer <token>` header. The dependency will decode and validate the JWT using `PyJWT`. If valid, it fetches the user from the database and returns the user object; otherwise, it raises an `HTTPException`. Implement the `GET /api/auth/me` endpoint and apply the dependency to protect it. The endpoint should return the authenticated user's data.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop Password Reset Flow with Email Integration",
        "description": "Create the functionality for users to reset their forgotten passwords. This includes requesting a reset link via email and submitting a new password using a secure token.",
        "details": "Implement `POST /api/password-reset/request` which generates a unique token, stores it in `password_reset_tokens` with an expiration, and sends an email using smtp2go. The email will contain a link to the frontend reset page. Implement `POST /api/password-reset/submit` which validates the token, checks for expiration, and updates the user's password hash.",
        "testStrategy": "Mock the SMTP client. Test the request endpoint to ensure a token is generated and stored. Test the submit endpoint with a valid token, an expired token, and an invalid token. Verify the user's password is changed successfully upon valid submission.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement `password_reset_tokens` Database Model",
            "description": "Create the database schema and corresponding application model for storing password reset tokens. This table will link a secure token to a user and include an expiration timestamp.",
            "dependencies": [],
            "details": "The schema for the `password_reset_tokens` table should include columns for a unique token string, a foreign key to the user's ID, and a `expires_at` timestamp. A database migration script must be created to apply this schema change.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Develop `POST /api/password-reset/request` Endpoint with Email Integration",
            "description": "Implement the API endpoint that allows a user to request a password reset link. This involves generating a secure token, storing it, and sending an email to the user via the smtp2go service.",
            "dependencies": [
              "3.1"
            ],
            "details": "This endpoint will receive a user's email. It will then generate a unique, secure token, save it to the `password_reset_tokens` table with a 1-hour expiration, and use the smtp2go client to send an email containing a link to the frontend password reset page with the token as a query parameter.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop `POST /api/password-reset/submit` Endpoint",
            "description": "Implement the API endpoint that allows a user to set a new password using a valid reset token. The endpoint must validate the token and securely update the user's password hash.",
            "dependencies": [
              "3.1"
            ],
            "details": "This endpoint will accept a reset token and a new password. The logic must verify that the token exists in the database and has not expired. If valid, it will hash the new password and update the user's record. The used token must be invalidated or deleted to prevent reuse.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Seed Canonical NFL Teams Data",
        "description": "Create a script or an initial data migration to populate the `teams` table with the official list of NFL teams, including their abbreviation, name, city, conference, and division.",
        "details": "Create a simple Python script or an Alembic data migration that inserts the 32 NFL teams into the `teams` table. The data should be sourced from a reliable list and use the canonical abbreviations specified in the PRD (e.g., 'LAR' for Los Angeles Rams). This script should be idempotent.",
        "testStrategy": "Run the seeding script. Query the `teams` table to confirm that all 32 teams have been inserted correctly with all required fields populated. The script should not create duplicates if run multiple times.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create idempotent Alembic data migration to seed 32 NFL teams",
            "description": "Add an Alembic data migration (or standalone script) that inserts the canonical 32 NFL teams into the `teams` table using upsert semantics. Include abbreviation normalization notes and a simple verification query for tests.",
            "dependencies": [],
            "details": "Implement a migration script that performs an UPSERT (insert on conflict do update) for each canonical team record (abbreviation, name, city, conference, division). Ensure the script is idempotent and safe to run multiple times. Add a small test or script that queries `SELECT COUNT(*) FROM teams` and verifies 32 rows exist after migration.",
            "status": "done",
            "testStrategy": "Run migration and run verification query. Re-run migration to confirm idempotency."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Admin Weeks Management API",
        "description": "Build the admin-only API endpoints for creating, updating, listing, and deleting weeks. This includes setting the `lock_time` and designating the current week for the season.",
        "details": "Create CRUD endpoints under `/api/weeks` and `/api/admin/*` guarded by an admin-only authorization check. Implement `POST /api/weeks` to create a new week, `PATCH /api/weeks/:id` to update details like `lock_time`, and `POST /api/admin/set-current-week` to toggle the `is_current` flag for a specific week (ensuring only one week is current at a time).",
        "testStrategy": "Write API tests for all week management endpoints. Test that non-admin users receive a 403 Forbidden error. Verify that creating and updating a week works as expected. Test the `set-current-week` logic to ensure it correctly unsets the previous current week.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Reusable Admin Authorization Dependency",
            "description": "Develop a reusable dependency that can be injected into API routes to verify that the current authenticated user has administrative privileges. This will protect all admin-only endpoints.",
            "dependencies": [],
            "details": "The dependency should decode the JWT provided in the request, retrieve the associated user, and check for an 'is_admin' flag or role. If the user is not an administrator, the dependency should raise an HTTP 403 Forbidden exception.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Standard CRUD Endpoints for Weeks",
            "description": "Build the standard Create, Read, Update, and Delete endpoints for managing the 'weeks' resource. These endpoints will be protected by the admin authorization dependency.",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement `POST /api/weeks` to create a new week, `GET /api/weeks` to list all weeks, `PATCH /api/weeks/:id` to update details like `lock_time`, and `DELETE /api/weeks/:id`. Secure all of these endpoints using the admin authorization dependency created in the previous subtask.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement 'Set Current Week' Business Logic Endpoint",
            "description": "Create the specialized admin endpoint to designate a specific week as the current one for the season, ensuring that only one week can be marked as current at any time.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Implement the `POST /api/admin/set-current-week` endpoint. It should accept a `week_id`. The service logic must perform a transaction that first sets `is_current = false` for all other weeks and then sets `is_current = true` for the specified week_id. This endpoint must also be protected by the admin authorization dependency.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Develop Internal ESPN Game Sync Job",
        "description": "Create a background job, exposed via a protected internal endpoint, to fetch weekly game schedules and results from the ESPN API and populate the `games` table.",
        "details": "Implement the `POST /internal/sync-games/espn` endpoint. This endpoint will fetch data from the specified ESPN URL. The logic must handle team abbreviation normalization (e.g., 'JAC' to 'JAX'), map ESPN game statuses to the internal `scheduled|in_progress|final` enum, and use an upsert strategy (delete all games for the target week, then insert the new set) to prevent data drift. Protect this endpoint with a secret token passed in a header.",
        "testStrategy": "Mock the ESPN API response. Test the sync logic to ensure it correctly parses the data, normalizes abbreviations, and populates the `games` table. Verify the delete-then-insert logic works correctly. Test the endpoint's security by calling it with and without the correct auth token.",
        "priority": "high",
        "dependencies": [
          4,
          5
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Secure POST /internal/sync-games/espn Endpoint",
            "description": "Create the FastAPI endpoint, implement security, and orchestrate the sync process by calling the data fetching, transformation, and database services.",
            "dependencies": [
              "6.4"
            ],
            "details": "Define the `POST /internal/sync-games/espn` route. Implement a dependency to validate a secret `X-Internal-Sync-Token` header against an environment variable. This endpoint will orchestrate the calls to the ESPN client, the transformation service, and finally the database sync service.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create ESPN API Client for Game Data Fetching",
            "description": "Implement a client or service function dedicated to fetching weekly game schedule and result data from the specified ESPN API URL.",
            "dependencies": [],
            "details": "Create a reusable function or class that handles making the HTTP GET request to the ESPN API. It should handle potential network errors, timeouts, and non-200 status codes gracefully. The function will accept parameters like year and week to construct the correct API URL and will return the raw JSON response.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop Data Transformation and Normalization Service",
            "description": "Create a service that takes the raw JSON response from the ESPN API and transforms it into the application's internal `Game` model format.",
            "dependencies": [
              "6.2"
            ],
            "details": "This service will parse the API response. It must include logic to normalize team abbreviations (e.g., 'JAC' to 'JAX'). It will also map the various ESPN game statuses to the internal enum values (`scheduled`, `in_progress`, `final`). The output should be a list of `Game` objects ready for database insertion.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement Transactional Database Sync Logic",
            "description": "Implement the database logic to persist the transformed game data using a transactional delete-then-insert strategy.",
            "dependencies": [
              "6.3"
            ],
            "details": "Create a database service function that accepts a list of transformed `Game` objects and the target week. Within a single database transaction, it will first execute a `DELETE` statement to remove all existing games for that specific week and year. Then, it will execute an `INSERT` statement to add the new set of games.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Player Entries Management API",
        "description": "Develop API endpoints for authenticated players to create, view, rename, and delete their own entries. Destructive actions (rename, delete) should be locked after Week 1 begins.",
        "details": "Create REST endpoints: `POST /api/entries`, `GET /api/users/:userId/entries`, `PATCH /api/entries/:id`, `DELETE /api/entries/:id`. Implement authorization logic to ensure users can only manage their own entries. For PATCH and DELETE, add a check against the current week's status to prevent modifications after the season starts (e.g., after Week 1 lock time).",
        "testStrategy": "Write API tests where a user attempts to create, read, update, and delete their own entry. Test that a user cannot access or modify another user's entries. Test the pre-Week 1 lock by attempting to rename/delete an entry after a mock Week 1 has locked.",
        "priority": "high",
        "dependencies": [
          2,
          5
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Create and List Entry Endpoints",
            "description": "Develop the `POST /api/entries` and `GET /api/users/:userId/entries` endpoints. This includes implementing ownership authorization to ensure users can only create entries for themselves and view their own list of entries.",
            "dependencies": [],
            "details": "Create the service logic and API routes for creating a new entry associated with the authenticated user. Implement the endpoint to retrieve all entries for a given user, ensuring the request is authorized. Add basic validation for required fields like entry name.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Update and Delete Entry Endpoints with Locking Logic",
            "description": "Develop the `PATCH /api/entries/:id` and `DELETE /api/entries/:id` endpoints. These destructive actions must be protected by both ownership checks and a business rule that prevents modifications after Week 1 has locked.",
            "dependencies": [
              "7.1"
            ],
            "details": "For both PATCH and DELETE operations, first verify that the authenticated user is the owner of the entry. Then, implement a check against the season's schedule to see if the Week 1 lock time has passed. If it has, the request should be rejected with an appropriate error message.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Enforce Unique Entry Names Per User Per Season",
            "description": "Implement validation logic in the create and update services to enforce that an entry's name must be unique for a given user within the current season. This prevents a user from creating duplicate or confusingly named entries.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Modify the service logic for `POST /api/entries` and `PATCH /api/entries/:id`. Before creating or updating an entry's name, query the database to ensure no other entry owned by the same user in the current season already has that name. Return a 409 Conflict error if a duplicate is found.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement Weekly Pick Submission API",
        "description": "Build the core API for players to submit and edit their weekly pick for each entry, including all critical validation rules.",
        "details": "Create `POST /api/picks` and `PATCH /api/picks/:id`. The service logic must enforce three key rules: 1) The submission time is before the `week.lock_time`. 2) The chosen team has not been previously picked by that entry in the current season (query historical picks). 3) A pick for this entry/week combination doesn't already exist (rely on the `UNIQUE(entry_id, week_id)` database constraint).",
        "testStrategy": "Test pick submission under various conditions: before the lock, after the lock (should fail). Test picking a new team, and picking a previously used team (should fail). Test creating a new pick and then editing it. Test submitting a pick for an entry the user does not own (should fail).",
        "priority": "high",
        "dependencies": [
          7
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Basic POST and PATCH Endpoints with Ownership Validation",
            "description": "Implement the `POST /api/picks` and `PATCH /api/picks/:id` endpoints. Include middleware or service logic to verify that the authenticated user owns the entry for which the pick is being submitted or modified.",
            "dependencies": [],
            "details": "This involves setting up the basic route handlers, defining request/response models, and adding an authorization check to ensure `entry.user_id == current_user.id` before proceeding.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Week Lock Time Validation",
            "description": "Add service logic to both the POST and PATCH endpoints to check if the submission time is before the `week.lock_time`. If the submission is after the lock time, the API should return an appropriate error.",
            "dependencies": [
              "8.1"
            ],
            "details": "The service function will need to fetch the current week's data, compare the current server timestamp against the `lock_time` field, and raise an HTTP exception (e.g., 403 Forbidden) if the deadline has passed.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement 'No Repeat Team' Validation",
            "description": "Implement the service logic to ensure the chosen team has not been previously picked by the same entry within the current season. This requires querying all historical picks for the given entry.",
            "dependencies": [
              "8.1"
            ],
            "details": "Before creating or updating a pick, the service must perform a database query to fetch all previously picked teams for the entry (e.g., `SELECT team_id FROM picks WHERE entry_id = :entry_id`). If the submitted `team_id` is in the results, return a validation error.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Handle Unique Constraint Violation for Entry/Week",
            "description": "Add specific error handling to the `POST /api/picks` endpoint to catch the `UNIQUE(entry_id, week_id)` database constraint violation and return a user-friendly error.",
            "dependencies": [
              "8.1"
            ],
            "details": "Wrap the database insertion logic in a try/except block. Catch the specific database integrity error and return an HTTP 409 Conflict error, suggesting the user should use the PATCH endpoint to edit their existing pick.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 9,
        "title": "Develop Game Finalization and Pick Resolution Logic",
        "description": "Create an admin-triggered process to finalize game scores for a week, update the status of all related picks (win/loss), and mark entries as eliminated.",
        "details": "Implement the `POST /api/admin/weeks/:weekId/finalize-scores` endpoint. This function will: 1) Accept final scores for games in the specified week. 2) Update the `games` table with scores and 'final' status. 3) Iterate through all picks for that week. 4) Determine the winning team for each game. 5) Update each pick's `result` to 'win' or 'loss'. 6) For any pick that is a 'loss', update the corresponding entry's `is_eliminated` flag to true.",
        "testStrategy": "Set up a test week with games, entries, and picks. Call the finalize endpoint with mock scores. Verify that game statuses and scores are updated correctly. Check that picks are correctly marked as 'win' or 'loss'. Confirm that entries with losing picks are marked as eliminated.",
        "priority": "medium",
        "dependencies": [
          6,
          8
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Admin-Protected Finalize Scores Endpoint",
            "description": "Implement the `POST /api/admin/weeks/:weekId/finalize-scores` route and controller. This endpoint will serve as the entry point for the game finalization process and must be protected to ensure only administrators can trigger it.",
            "dependencies": [],
            "details": "Set up the API route using the specified path. Implement middleware to check for admin authentication/authorization. The controller should accept `weekId` from the path and a request body containing final scores for the games of that week. It will orchestrate calls to the subsequent services.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Game Score and Status Update Logic",
            "description": "Develop the service logic to process the final scores received by the endpoint. This service will update the `games` table for the specified week, setting the final scores and changing the game status to 'final'.",
            "dependencies": [],
            "details": "Create a function/service that takes a week ID and a list of game scores as input. It should perform a bulk update or iterate through the games of the week to update their `home_team_score`, `away_team_score`, and `status` fields in the database. Ensure proper transaction handling to maintain data integrity.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop Pick Resolution Service",
            "description": "Create a service to iterate through all user picks for the finalized week and update their results. This involves comparing each pick against the final game outcomes to determine if it was a 'win' or a 'loss'.",
            "dependencies": [],
            "details": "This service will be called after the games are updated. It needs to: 1) Fetch all games for the week with their final scores. 2) Fetch all picks for that same week. 3) For each pick, determine the winning team of the corresponding game. 4) Compare the picked team with the winning team and update the `result` column in the `picks` table to either 'win' or 'loss'. This should be done as a single, efficient batch operation.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement Entry Elimination Logic",
            "description": "Develop the final step of the process, which identifies all entries that made a losing pick for the week and marks them as eliminated.",
            "dependencies": [],
            "details": "After all picks have been resolved, this service will query the `picks` table for any records with a `result` of 'loss' for the given week. For each losing pick, it will retrieve the associated `entry_id` and update the `is_eliminated` flag to `true` in the `entries` table. This should handle multiple losing picks efficiently, potentially updating all affected entries in a single query.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement Public Pre-Reveal and Site Time Endpoints",
        "description": "Create the public, unauthenticated endpoints needed for the main dashboard and general site information before the weekly lock, including the current week's data and a server time endpoint.",
        "details": "Implement the following GET endpoints: `/api/weeks/current` to fetch basic info about the current week (number, lock time), `/api/teams` to list all NFL teams, and `/api/site-time` which returns the current server time in ISO format. This `site-time` endpoint is crucial for the frontend to display an accurate countdown timer, mitigating client-side clock skew.",
        "testStrategy": "Call the public endpoints without any authentication to ensure they are accessible. Verify the data format and content for each endpoint. Check that `/api/site-time` returns a valid ISO 8601 timestamp.",
        "priority": "medium",
        "dependencies": [
          4,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Post-Reveal Data Endpoints",
        "description": "Develop the API endpoints that reveal pick distributions and results after the weekly lock time has passed.",
        "details": "Implement `GET /api/weeks/:id/reveal-snapshot`. This endpoint must first check if `now() >= week.lock_time`. If not, it should return a minimal payload or an error. If the time has passed, it will query all picks for the week, aggregate the counts for each team, and return a summary of pick distribution, game results, and survivor counts. Avoid exposing individual user picks unless the design calls for it.",
        "testStrategy": "Test the reveal endpoint before the mock lock time; it should not reveal pick data. Advance the mock server time past the lock time and test again; it should now return the full aggregated data. Verify the pick counts and game results in the response are accurate.",
        "priority": "medium",
        "dependencies": [
          8,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Create Player Dashboard Aggregation API",
        "description": "Build a single, protected endpoint to provide all necessary data for a logged-in player's dashboard view.",
        "details": "Create a `GET /api/dashboard` endpoint that requires authentication. This endpoint will aggregate data for the logged-in user, including: their active entries and their status (`is_eliminated`), their pick for the current week for each entry (if made), and the current week's information (countdown, lock time). This avoids multiple frontend requests.",
        "testStrategy": "Log in as a test user and call the dashboard endpoint. Verify that it returns only that user's entries and picks. Test with a user who has made a pick and one who has not. Test with an eliminated entry to ensure the status is reflected correctly.",
        "priority": "medium",
        "dependencies": [
          2,
          7,
          8,
          10
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define JSON Response Schema for Dashboard API",
            "description": "Document and define the Pydantic model or JSON schema for the `GET /api/dashboard` endpoint. This schema will serve as the contract for the frontend and will include fields for user entries, their statuses, current week picks, and overall week information like lock times.",
            "dependencies": [],
            "details": "The schema should be well-structured to be easily consumed by the frontend. It should include a list of entries, where each entry object contains its ID, name, `is_eliminated` status, and an optional `current_pick` object. The top-level response should also contain a `current_week` object with `week_number`, `lock_time`, and a countdown value.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Query to Fetch User's Entries",
            "description": "Create the database query logic to retrieve all entries associated with the authenticated user. The query should include the entry's primary details and its elimination status.",
            "dependencies": [
              "12.1"
            ],
            "details": "This involves querying the `entries` table, filtering by the `user_id` from the authentication token. The query should select fields like `id`, `name`, and `is_eliminated`. This logic should be encapsulated in a reusable function or repository method.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement Query to Fetch Current Week's Picks for Entries",
            "description": "Develop the database query logic to fetch the current week's pick for a given list of entry IDs. This will be used to supplement the entry data with the user's selection for the week.",
            "dependencies": [
              "12.2"
            ],
            "details": "The function should accept a list of `entry_id`s. It will query the `picks` table, filtering by `entry_id` and the `week_id` corresponding to the current week. The query should return the selected `team_id` for each entry that has a pick. The result should be structured for easy mapping back to the entries.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Build and Implement the /api/dashboard Endpoint",
            "description": "Create the final `GET /api/dashboard` FastAPI endpoint. This endpoint will orchestrate the calls to fetch user entries and their picks, combine the data, and return it in the predefined JSON structure.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3"
            ],
            "details": "The endpoint will first require user authentication. It will then call the function from subtask 12.2 to get the user's entries. Next, it will use the entry IDs to call the function from subtask 12.3 to get the picks. Finally, it will merge these two datasets, add the current week's information (e.g., lock time), and serialize the final payload using the Pydantic model from subtask 12.1 before returning the HTTP response.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 13,
        "title": "Build Admin User and Entry Management APIs",
        "description": "Expand the admin console functionality with APIs to manage all users and entries in the system.",
        "details": "Implement admin-only endpoints: `GET /api/admin/users` and `PATCH /api/admin/users/:userId` for user management. Create `GET /api/admin/entries` to list all entries with filtering capabilities. Implement `PATCH /api/admin/entries/:entryId/payment` and `PATCH /api/admin/entries/:entryId/elimination` for admins to manually override payment status and elimination status.",
        "testStrategy": "Test all endpoints with an admin user token to verify functionality. Test with a regular user token to ensure access is denied. For patch endpoints, verify that the specific fields (e.g., `is_paid`, `is_eliminated`) are updated correctly in the database without affecting other data.",
        "priority": "low",
        "dependencies": [
          2,
          7
        ],
        "status": "in-progress",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Admin Broadcast Email System",
        "description": "Create an endpoint for admins to send broadcast emails to players, with options for filtering the recipient list.",
        "details": "Develop the `POST /api/admin/broadcast` endpoint. It should accept a subject, body, and a filter parameter (e.g., 'all', 'active', 'unpaid'). The backend logic will query the `users` and `entries` tables to build the recipient list based on the filter, and then loop through the list, sending an email to each user via the configured smtp2go service.",
        "testStrategy": "Mock the SMTP service. Call the broadcast endpoint with different filters and verify that the mock service is called with the correct list of recipient email addresses. Test the endpoint security to ensure only admins can send broadcasts.",
        "priority": "low",
        "dependencies": [
          3,
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Develop Season History Matrix API",
        "description": "Implement an endpoint to generate the full season history matrix, showing each entry's pick for every week.",
        "details": "Create the `GET /api/history/matrix` endpoint. The initial implementation will perform a database query joining `entries`, `picks`, and `weeks` to construct the matrix data structure. As per the PRD, focus on an optimized query with proper indexes first. The response should be a JSON object structured for easy rendering as a table on the frontend (e.g., rows of entries, with columns for each week's pick).",
        "testStrategy": "Populate the database with several weeks of historical data for multiple entries. Call the history matrix endpoint and validate the structure and correctness of the returned data against the source data. Use `EXPLAIN ANALYZE` on the underlying query to check for performance bottlenecks.",
        "priority": "low",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define JSON Response Schema for History Matrix",
            "description": "Document and define the precise JSON structure for the `/api/history/matrix` endpoint response. This schema should be optimized for easy consumption and rendering as a table on the frontend.",
            "dependencies": [],
            "details": "The schema should clearly outline the structure, such as an array of entry objects, where each object contains the entry's name and a list or map of their picks for each week of the season. This definition will serve as the contract for both the backend implementation and the frontend consumer.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Initial Database Query for Raw Matrix Data",
            "description": "Develop a first-pass SQL query that joins the `entries`, `picks`, and `weeks` tables to gather all the raw data required to build the history matrix. The focus at this stage is on correctness, not performance.",
            "dependencies": [],
            "details": "The query should retrieve the entry name, the week number, and the team picked for every pick made in the season. This will result in a flat list of records that will be processed and structured in a later step.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Profile and Optimize the History Matrix Query",
            "description": "Use the database's `EXPLAIN ANALYZE` functionality to profile the initial query's performance. Based on the analysis, apply optimizations such as adding indexes to relevant columns (e.g., foreign keys) to ensure efficient data retrieval.",
            "dependencies": [
              "15.2"
            ],
            "details": "The query will be tested against a populated database to simulate real-world load. The query plan will be inspected for inefficiencies like sequential scans. Necessary indexes on tables like `picks` (on `entry_id` and `week_id`) will be created and verified to improve query speed.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Build GET /api/history/matrix Endpoint",
            "description": "Implement the `GET /api/history/matrix` API endpoint. This endpoint will execute the optimized query, process the resulting data, and format it into the JSON response structure defined in the first subtask.",
            "dependencies": [
              "15.1",
              "15.3"
            ],
            "details": "The endpoint logic will fetch the flat data from the database using the optimized query. It will then iterate through the results to build the nested JSON object, grouping picks by entry. The final, structured data will be returned as the API response.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 16,
        "title": "Create Legacy Data Import Tooling from GCS",
        "description": "Build a secure, idempotent tool to migrate existing user, entry, pick, and game data from JSON files in Google Cloud Storage into the new Supabase database.",
        "details": "Develop a CLI script (`scripts/import_from_gcs`) or a protected internal endpoint (`POST /internal/import/from-gcs`). The tool must process files in the correct order: teams, users, weeks, games, entries, picks. Use upsert logic to ensure idempotency. Implement `--dry-run` functionality. All date/time strings must be parsed and converted to UTC before insertion.",
        "testStrategy": "Create a set of sample GCS JSON files with valid and invalid data (e.g., a pick for a non-existent user). Run the import in `--dry-run` mode and verify the report. Run a real import against a test database and verify that all data is inserted correctly and referential integrity is maintained. Verify that running the import a second time does not create duplicate data.",
        "priority": "medium",
        "dependencies": [
          1,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup CLI Script Structure and GCS Client",
            "description": "Create the initial CLI script (`scripts/import_from_gcs`) with argument parsing for options like `--dry-run`. Implement the Google Cloud Storage client setup and authentication to list and download JSON files from the specified bucket.",
            "dependencies": [],
            "details": "The script should be able to connect to GCS, authenticate using service account credentials, and list the relevant JSON files (teams.json, users.json, etc.). It should parse command-line arguments, specifically a `--dry-run` flag that will be used in later subtasks.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Import Logic for Users and Teams",
            "description": "Develop the functionality to parse `users.json` and `teams.json` files downloaded from GCS. The script will transform the data and insert it into the `users` and `teams` tables in the Supabase database.",
            "dependencies": [
              "16.1"
            ],
            "details": "This subtask focuses on the simplest entities that have no foreign key dependencies on other imported data. The logic should handle parsing the JSON structure, mapping fields to the database schema, and performing the initial database insertions. Date/time strings for user creation must be converted to UTC.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement Import Logic for Weeks and Games",
            "description": "Add logic to process `weeks.json` and `games.json`. This involves parsing the files, converting all date/time strings to UTC, and inserting the data into the `weeks` and `games` tables, correctly linking games to their respective weeks and teams.",
            "dependencies": [
              "16.2"
            ],
            "details": "Games have foreign keys to the `teams` and `weeks` tables. The import logic must correctly resolve these relationships using the data imported in the previous step. All game times and week lock times must be parsed and stored in UTC.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement Import Logic for Entries and Picks",
            "description": "Implement the final data import stage for `entries.json` and `picks.json`. This logic will link entries to users and picks to entries, users, games, and weeks, ensuring all referential integrity is maintained.",
            "dependencies": [
              "16.3"
            ],
            "details": "This is the most complex part of the data import due to multiple foreign key relationships. The script must look up the IDs of users, games, and weeks from the database to correctly populate the `entries` and `picks` tables.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Implement Idempotency (Upsert) and Integrate Dry-Run",
            "description": "Refactor the import logic for all data types to be idempotent using an 'upsert' strategy. Fully integrate the `--dry-run` flag to simulate the entire import process and report on what would be created or updated without making any database changes.",
            "dependencies": [
              "16.4"
            ],
            "details": "Modify all database insertion logic to check for existing records and update them if necessary, preventing duplicates on re-runs. The `--dry-run` mode should connect to GCS, parse all files, and print a detailed summary of actions (e.g., 'DRY-RUN: Would create 50 users', 'DRY-RUN: Would update 10 games') without committing any transactions.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-09-14T23:24:48.603Z",
      "updated": "2025-09-17T11:49:18.633Z",
      "description": "Tasks for master context"
    }
  }
}